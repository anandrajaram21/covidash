{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holt Winters Exponential Smoothing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To import the main.py file\n",
    "sys.path.append('../')\n",
    "from python_files import main\n",
    "\n",
    "# Getting all the data\n",
    "confirmed_global, deaths_global, recovered_global, country_cases = main.collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(country_name):\n",
    "    # Getting the confirmed cases of that country\n",
    "    cases = main.get_new_cases(country_name)\n",
    "    \n",
    "    # Removing the zero values \n",
    "    is_0 = cases['cases'] != 0\n",
    "    cases = cases[is_0]\n",
    "    \n",
    "    # Making the training and test sets\n",
    "    split_ratio = 0.80\n",
    "    train_size = int(split_ratio * len(cases))\n",
    "    train_df, test_df = cases.iloc[:train_size, :], cases.iloc[train_size:, :]\n",
    "    train_df, test_df = pd.Series(train_df['cases'].values, train_df['date']), pd.Series(test_df['cases'].values, test_df['date'])\n",
    "    cases = pd.Series(cases['cases'].values, cases['date'])\n",
    "    \n",
    "    # Model\n",
    "    model = Holt(train_df, initialization_method = 'heuristic').fit(smoothing_level = 0.3, smoothing_trend = 2.6, optimized = True)\n",
    "    forecast1 = model.forecast(len(test_df))\n",
    "    \n",
    "    print(mape(forecast1, test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.081015186205162\n"
     ]
    }
   ],
   "source": [
    "predict('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4730656405466918\n"
     ]
    }
   ],
   "source": [
    "predict('Russia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_holt(country_name, sl, st):\n",
    "    # Getting the confirmed cases of that country\n",
    "    cases = main.get_new_cases(country_name)\n",
    "    \n",
    "    # Removing the zero values \n",
    "    is_0 = cases['cases'] != 0\n",
    "    cases = cases[is_0]\n",
    "    \n",
    "    # Making the training and test sets\n",
    "    split_ratio = 0.80\n",
    "    train_size = int(split_ratio * len(cases))\n",
    "    train_df, test_df = cases.iloc[:train_size, :], cases.iloc[train_size:, :]\n",
    "    train_df, test_df = pd.Series(train_df['cases'].values, train_df['date']), pd.Series(test_df['cases'].values, test_df['date'])\n",
    "    cases = pd.Series(cases['cases'].values, cases['date'])\n",
    "    \n",
    "    # Model\n",
    "    model = Holt(train_df, initialization_method = 'heuristic').fit(smoothing_level = sl, smoothing_trend = st, optimized = True)\n",
    "    forecast1 = model.forecast(len(test_df))\n",
    "    \n",
    "    return (mape(forecast1, test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4195715097104795 0.3 1.0\n",
      "CPU times: user 3.13 s, sys: 3.99 ms, total: 3.13 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Custom grid search\n",
    "sl = [i/10 for i in range(1, 11)]\n",
    "st = [i/10 for i in range(1, 11)]\n",
    "lowest = 100\n",
    "sl_l = None\n",
    "st_l = None\n",
    "\n",
    "for sli in sl:\n",
    "    for sti in st:\n",
    "        ma = grid_search_holt('India', sli, sti)\n",
    "        if ma <= lowest:\n",
    "            lowest = ma\n",
    "            sl_l = sli\n",
    "            st_l = sti\n",
    "print(lowest, sl_l, st_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
